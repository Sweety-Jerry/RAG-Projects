from llama_index.core.readers import download_loader

PDFReader = download_loader("PDFReader")
loader = PDFReader()
documents = loader.load_data(file="ragg.pdf")

from llama_index.core.node_parser import SimpleNodeParser
parser = SimpleNodeParser()
nodes = parser.get_nodes_from_documents(documents)

from llama_index.core import VectorStoreIndex, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# Use a local embedding model
Settings.embed_model = HuggingFaceEmbedding(model_name="BAAI/bge-small-en-v1.5")

index = VectorStoreIndex(nodes)

from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core import Settings

# Configure a retriever
retriever = index.as_retriever()

# Set the global LLM setting to None
Settings.llm = None

# Configure a query engine
query_engine = RetrieverQueryEngine.from_args(retriever, llm=None)

# Query the document
response = query_engine.query("What is the main idea of this document?")
print(response)

%pip install llama_index

%pip install llama-index-embeddings-huggingface transformers accelerate
